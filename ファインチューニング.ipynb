{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ファインチューニング",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOC+LJ3GRkjXHOc4i3xj6xF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7521d46d11142298ac046135fbd73c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66b4ea4e96334cd3988ddf11de31a7b8",
              "IPY_MODEL_1aa6ce35edc94b4c8adeab3ec8c6a22b",
              "IPY_MODEL_0f3f12b60116422da2fdc66ec1ee7d5a"
            ],
            "layout": "IPY_MODEL_07c8d7dc3a68439baad1aaeddc3695f1"
          }
        },
        "66b4ea4e96334cd3988ddf11de31a7b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12f541ae167146f6ad741e6356f7d53a",
            "placeholder": "​",
            "style": "IPY_MODEL_acc97a0a6948442a9de31ebbe18c6f49",
            "value": "100%"
          }
        },
        "1aa6ce35edc94b4c8adeab3ec8c6a22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5710a87e19e1415091c2277b5e820e68",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4379c188273b480a80ffc79da65d18e5",
            "value": 553433881
          }
        },
        "0f3f12b60116422da2fdc66ec1ee7d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5932a2dd22524afe9706880ab0cb0e1c",
            "placeholder": "​",
            "style": "IPY_MODEL_d36204cc093a43f9b46fb424d37dcfeb",
            "value": " 528M/528M [00:02&lt;00:00, 204MB/s]"
          }
        },
        "07c8d7dc3a68439baad1aaeddc3695f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f541ae167146f6ad741e6356f7d53a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acc97a0a6948442a9de31ebbe18c6f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5710a87e19e1415091c2277b5e820e68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4379c188273b480a80ffc79da65d18e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5932a2dd22524afe9706880ab0cb0e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36204cc093a43f9b46fb424d37dcfeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matzmtok/AdvancedPytorch/blob/main/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%B3%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ファインチューニングの実装\n",
        "\n",
        "ファインチューニングを使用して、手元にある少量のデータを学習させて、オリジナルの画像分類モデルを構築する。\n",
        "\n",
        "アリとハチの画像を分類するモデルを学習させる。\n",
        "\n",
        "1. PytorchでGPUを使用する実装コードをかけるようになる\n",
        "2. 最適化手法の設定において、層ごとに異なる学習率を設定したファインチューニングを実装できるようになる\n",
        "3. 学習したネットワークを保存・ロードできるようになる\n",
        "\n",
        "## ファインチューニング\n",
        "\n",
        "ファインチューニングとは、学習済みモデルをベースに出力層などを変更したモデルを構築し、自前のデータでニューラルネットワーク・モデルの結合パラメータを学習させる手法です。\n",
        "転移学習とは異なり、出力層および出力層に近い部分だけでなく、全層のパラメータを再学習させます。ただし、入力層に近い部分のパラメータの学習率は小さく設定し、出力層に近いパラメータの学習率は大きく設定することが一般的。\n",
        "\n",
        "ファインチューニングは転移学習同様に、学習済みモデルを利用するため、自前のデータが少量でも性能の良いディープラーニングを実現しやすい。\n",
        "\n",
        "## フォルダ準備と事前準備\n",
        "\n",
        "## DatasetとDataLoaderを作成\n",
        "\n"
      ],
      "metadata": {
        "id": "a-NuSZx0QiE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Gx6eDIb9ZPFT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIn2A50pYeyc",
        "outputId": "a2c21e79-b2db-4198-84b6-5a36e53db159"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageTransform():\n",
        "  def __init__(self, resize, mean, std):\n",
        "    self.data_transform = {\n",
        "        'train': transforms.Compose([\n",
        "          transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "          transforms.Resize(resize),\n",
        "          transforms.CenterCrop(resize),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean, std)\n",
        "        ])\n",
        "    }\n",
        "\n",
        "  def __call__(self, img, phase='train'):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    phase : 'train' or 'val'\n",
        "    引数に指定したimgに対してtransformを適用する\n",
        "    \"\"\"\n",
        "    return self.data_transform[phase](img)\n",
        "\n",
        "def make_datapath_list(phase=\"train\"):\n",
        "  \"\"\"\n",
        "  対象フォルダ内の画像のリストを生成する\n",
        "  \"\"\"\n",
        "  rootpath = \"/content/drive/MyDrive/datasets/hymenoptera_data\"\n",
        "  target_path = os.path.join(rootpath, phase ,\"**/*.jpg\")\n",
        "  print(f\"target path : {target_path}\")\n",
        "  path_list = []\n",
        "\n",
        "  for path in glob.glob(target_path):\n",
        "    path_list.append(path)\n",
        "\n",
        "  return path_list\n",
        "\n",
        "class HymenopteraDataset(data.Dataset):\n",
        "  \"\"\"\n",
        "  アリとハチの画像のDatastクラス\n",
        "  \"\"\"\n",
        "  def __init__(self, file_list, transform=None, phase='train'):\n",
        "    self.file_list = file_list\n",
        "    self.transform = transform\n",
        "    self.phase = phase\n",
        "\n",
        "  def __len__(self):\n",
        "    \"\"\"\n",
        "    画像の枚数を返す\n",
        "    \"\"\"\n",
        "    return len(self.file_list)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    \"\"\"\n",
        "    前処理をした画像のTensor形式のデータトラベルを取得\n",
        "    \"\"\"\n",
        "    img_path = self.file_list[index]\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    img_transformed = self.transform(img, self.phase)\n",
        "\n",
        "    train_idx = len(\"/content/drive/MyDrive/datasets/hymenoptera_data/train/\")\n",
        "    val_idx = len(\"/content/drive/MyDrive/datasets/hymenoptera_data/val/\")\n",
        "    if self.phase == \"train\":\n",
        "      label = img_path[train_idx:train_idx+4]\n",
        "    elif self.phase == \"val\":\n",
        "      label = img_path[val_idx:val_idx+4]\n",
        "\n",
        "    if label == \"ants\":\n",
        "      label = 0\n",
        "    elif label == \"bees\":\n",
        "      label = 1\n",
        "    \n",
        "    return img_transformed, label\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "6eNADyQdZmiU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = make_datapath_list(phase=\"train\")\n",
        "val_list = make_datapath_list(phase=\"val\")\n",
        "\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.299, 0.224, 0.225)\n",
        "\n",
        "train_dataset = HymenopteraDataset(train_list, transform=ImageTransform(size, mean, std), phase=\"train\")\n",
        "val_dataset = HymenopteraDataset(val_list, transform=ImageTransform(size, mean, std),phase=\"val\")\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX6UYH4bTwzq",
        "outputId": "0dc95894-3449-4b1c-f956-ae813768a771"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target path : /content/drive/MyDrive/datasets/hymenoptera_data/train/**/*.jpg\n",
            "target path : /content/drive/MyDrive/datasets/hymenoptera_data/val/**/*.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ネットワークモデルの作成\n",
        "\n",
        "出力層を1000クラスからアリとハチの2クラスとなるように付け替える"
      ],
      "metadata": {
        "id": "iea7tjnNLbcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_pretrained = True\n",
        "net = models.vgg16(pretrained=use_pretrained)\n",
        "\n",
        "print(net)\n",
        "\n",
        "# 出力層の付替\n",
        "net.classifier[6] = nn.Linear(in_features=4096, out_features=2)\n",
        "\n",
        "#test\n",
        "net.train()\n",
        "\n",
        "print(net.named_parameters())\n",
        "\n",
        "\n",
        "print('network is configured! It\\'s ready to use.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930,
          "referenced_widgets": [
            "d7521d46d11142298ac046135fbd73c3",
            "66b4ea4e96334cd3988ddf11de31a7b8",
            "1aa6ce35edc94b4c8adeab3ec8c6a22b",
            "0f3f12b60116422da2fdc66ec1ee7d5a",
            "07c8d7dc3a68439baad1aaeddc3695f1",
            "12f541ae167146f6ad741e6356f7d53a",
            "acc97a0a6948442a9de31ebbe18c6f49",
            "5710a87e19e1415091c2277b5e820e68",
            "4379c188273b480a80ffc79da65d18e5",
            "5932a2dd22524afe9706880ab0cb0e1c",
            "d36204cc093a43f9b46fb424d37dcfeb"
          ]
        },
        "id": "9IB72Ei6L4Qd",
        "outputId": "3db86e9e-4a1e-4c79-895e-763cdda5f85d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7521d46d11142298ac046135fbd73c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "<generator object Module.named_parameters at 0x7f41be3f4cd0>\n",
            "network is configured! It's ready to use.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 損失関数を定義"
      ],
      "metadata": {
        "id": "1bhdwe2VM2HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "cidtFIdfND9l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 最適化手法を設定\n",
        "\n",
        "ファインチューニングでは、最適化手法の設定部分が転移学習と異なる。全層のパラメータを学習できるようにoptimizerを設定する。\n",
        "\n",
        "各層ごとに学習率を変えられるようにパラメータを設定する。\n",
        "VGG-16の前半のfeatureモジュールのパラメータ変数update_param_names_1に、後半の全層結合層のclassifierモジュールのうち、最初の2つの全層結合のパラメータを変数update_param_names_2に、そして付け替えた最後の全層結合層のパラメータ変数をupdate_param_names_3に格納し、それぞれを異なる学習率を適用する。\n"
      ],
      "metadata": {
        "id": "JRTDuYAnNLqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_to_update_1 = []\n",
        "params_to_update_2 = []\n",
        "params_to_update_3 = []\n",
        "\n",
        "update_params_names_1 = [\"features\"]\n",
        "update_params_names_2 = [\"classifier.0.weight\", \"classifier.0.bias\", \"classifier.3.weight\", \"classifier.3.bias\"]\n",
        "update_params_names_3 = [\"classifier.6.weight\", \"classifier.6.bias\"]\n",
        "\n",
        "for name, param in net.named_parameters():\n",
        "  if update_params_names_1[0] in name:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_1.append(param)\n",
        "    print(\"params_to_update_1に格納：\", name)\n",
        "\n",
        "  elif name in  update_params_names_2:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_2.append(param)\n",
        "    print(\"params_to_update_2に格納：\", name)\n",
        "\n",
        "  elif name in update_params_names_3:\n",
        "    param.requires_grad = True\n",
        "    params_to_update_3.append(param)\n",
        "    print(\"params_to_update_3に格納：\", name)\n",
        "    \n",
        "  else:\n",
        "    param.requires_grad = False\n",
        "\n",
        "optimizer = optim.SGD([\n",
        "  {'params': params_to_update_1, 'lr': 1e-4},\n",
        "  {'params': params_to_update_2, 'lr': 5e-4},\n",
        "  {'params': params_to_update_3, 'lr': 1e-3}\n",
        "], momentum=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GilXQaDUQh3x",
        "outputId": "92d36fc9-d4b7-474a-a910-7bc38ca03094"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params_to_update_1に格納： features.0.weight\n",
            "params_to_update_1に格納： features.0.bias\n",
            "params_to_update_1に格納： features.2.weight\n",
            "params_to_update_1に格納： features.2.bias\n",
            "params_to_update_1に格納： features.5.weight\n",
            "params_to_update_1に格納： features.5.bias\n",
            "params_to_update_1に格納： features.7.weight\n",
            "params_to_update_1に格納： features.7.bias\n",
            "params_to_update_1に格納： features.10.weight\n",
            "params_to_update_1に格納： features.10.bias\n",
            "params_to_update_1に格納： features.12.weight\n",
            "params_to_update_1に格納： features.12.bias\n",
            "params_to_update_1に格納： features.14.weight\n",
            "params_to_update_1に格納： features.14.bias\n",
            "params_to_update_1に格納： features.17.weight\n",
            "params_to_update_1に格納： features.17.bias\n",
            "params_to_update_1に格納： features.19.weight\n",
            "params_to_update_1に格納： features.19.bias\n",
            "params_to_update_1に格納： features.21.weight\n",
            "params_to_update_1に格納： features.21.bias\n",
            "params_to_update_1に格納： features.24.weight\n",
            "params_to_update_1に格納： features.24.bias\n",
            "params_to_update_1に格納： features.26.weight\n",
            "params_to_update_1に格納： features.26.bias\n",
            "params_to_update_1に格納： features.28.weight\n",
            "params_to_update_1に格納： features.28.bias\n",
            "params_to_update_2に格納： classifier.0.weight\n",
            "params_to_update_2に格納： classifier.0.bias\n",
            "params_to_update_2に格納： classifier.3.weight\n",
            "params_to_update_2に格納： classifier.3.bias\n",
            "params_to_update_3に格納： classifier.6.weight\n",
            "params_to_update_3に格納： classifier.6.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"使用デバイス：\", device)\n",
        "\n",
        "  net.to(device)\n",
        "\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{ num_epochs}\")\n",
        "    print('------------------------------')\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase =='train':\n",
        "        net.train()\n",
        "      else:\n",
        "        net.eval()\n",
        "\n",
        "      epoch_loss = 0.0\n",
        "      epoch_corrects = 0\n",
        "\n",
        "      # epoch 0 は学習しない。\n",
        "      # 未学習時の性能を確認するため\n",
        "      if (epoch == 0) and (phase == 'train'):\n",
        "        continue\n",
        "      \n",
        "      for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "        inputs = inputs.to(device)\n",
        "        print(labels)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          outputs = net(inputs) # 推論実行\n",
        "          loss = criterion(outputs, labels) # 損失計算\n",
        "          _, preds = torch.max(outputs, 1) # ラベルを予測\n",
        "\n",
        "          # 逆伝搬\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "          # 計算したロスを合計\n",
        "          epoch_loss += loss.item() * inputs.size(0)\n",
        "          epoch_corrects += torch.sum(preds == labels.data)\n",
        "      \n",
        "      # epochごとのLossと成果率を表示\n",
        "      epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "      epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "      print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PGQ3o0GKaily"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp4jR3eXfF6c",
        "outputId": "b451180e-533c-482b-c743-603986fdbd40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス： cuda:0\n",
            "Epoch 1/2\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 2/5 [00:23<00:34, 11.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:35<00:23, 11.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:47<00:11, 11.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:56<00:00, 11.36s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.8414 Acc: 0.3072\n",
            "Epoch 2/2\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
            "        1, 1, 1, 1, 0, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 1/8 [00:08<00:57,  8.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
            "        0, 0, 0, 1, 1, 1, 1, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 2/8 [00:14<00:42,  7.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
            "        0, 1, 0, 1, 1, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 3/8 [00:21<00:35,  7.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 4/8 [00:29<00:30,  7.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
            "        1, 0, 1, 1, 1, 0, 0, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 5/8 [00:34<00:19,  6.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
            "        1, 0, 1, 0, 0, 0, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 6/8 [00:40<00:12,  6.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
            "        1, 0, 0, 0, 1, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 7/8 [00:47<00:06,  6.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8/8 [00:54<00:00,  6.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5680 Acc: 0.6667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 1/5 [00:00<00:01,  2.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 2/5 [00:00<00:01,  2.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 3/5 [00:01<00:00,  2.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 4/5 [00:01<00:00,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5/5 [00:02<00:00,  2.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0])\n",
            "val Loss: 0.2451 Acc: 0.9085\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習したネットワークを保存・ロード\n",
        "\n",
        "ネットワークモデルの変数net に対して、.state_dict()でパラメータを辞書型変数として取り出し、torch.save()で保存する。\n",
        "\n"
      ],
      "metadata": {
        "id": "NkxmvAxHfNNr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/datasets/hymenoptera_data/artifact/weights_fine_tuning.pth\"\n",
        "torch.save(net.state_dict(), save_path)"
      ],
      "metadata": {
        "id": "uuLezIrYlQUn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データのロード\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZD5tfdzEloQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_path = \"/content/drive/MyDrive/datasets/hymenoptera_data/artifact\"\n",
        "\n",
        "load_weights = torch.load(load_path)\n",
        "net.load_state_dict(load_weights)\n",
        "\n",
        "# gpuで保存した重みをCPUにロードする場合\n",
        "# load_weights = torch.load(load_path, map_location={'cuda:0': 'cpu'})\n",
        "# net.load_state_dict(load_weighs)"
      ],
      "metadata": {
        "id": "AO-KizTjl_wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}